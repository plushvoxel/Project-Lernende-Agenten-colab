{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "intro_to_neural_nets.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "JndnmDMp66FL",
        "O2q5RRCKqYaU",
        "vvT2jDWjrKew"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/plushvoxel/Project-Lernende-Agenten-colab/blob/master/WorkingVersion1.0.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "JndnmDMp66FL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Copyright 2017 Google LLC."
      ]
    },
    {
      "metadata": {
        "id": "hMqWDc_m6rUC",
        "colab_type": "code",
        "colab": {},
        "cellView": "both"
      },
      "cell_type": "code",
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eV16J6oUY-HN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Creating a NN"
      ]
    },
    {
      "metadata": {
        "id": "J2kqX6VZTHUy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "First, let's load and prepare the data."
      ]
    },
    {
      "metadata": {
        "id": "AGOM1TUiKNdz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import math\n",
        "from urllib import request\n",
        "from IPython import display\n",
        "from matplotlib import cm\n",
        "from matplotlib import gridspec\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.data import Dataset\n",
        "from google.colab import files\n",
        "from tarfile import open as taropen\n",
        "from struct import unpack\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xwa02-_8PREz",
        "colab_type": "code",
        "colab": {},
        "cellView": "both"
      },
      "cell_type": "code",
      "source": [
        "training_set_size = 100 #@param {type:\"slider\", min:1, max:3000, step:1}\n",
        "validating_set_size = 10 #@param {type:\"slider\", min:1, max:1000, step:1}\n",
        "test_set_size = 10 #@param {type:\"slider\", min:1, max:1000, step:1}\n",
        "learning_rate = 0.3 #@param [\"3\", \"1\", \"0.3\", \"0.1\", \"0.03\", \"0.01\", \"0.003\", \"0.001\", \"0.0003\", \"0.0001\"] {type:\"raw\"}\n",
        "activation_function = \"RELU\" #@param [\"RELU\", \"Sigmoid\", \"Tanh\"]\n",
        "regression = \"None\" #@param [\"None\", \"L1\", \"L2\"]\n",
        "regression_rate = 3 #@param [\"3\", \"1\", \"0.3\", \"0.1\", \"0.03\", \"0.01\", \"0.003\", \"0.001\"] {type:\"raw\"}\n",
        "steps = 20 #@param {type:\"slider\", min:1, max:100, step:1}\n",
        "batch_size = 5 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "model = [2048, 500]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E-6f-hz4PPBA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "b70813cd-dd04-4877-9e10-ea06943083ad"
      },
      "cell_type": "code",
      "source": [
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = '{:.1f}'.format\n",
        "\n",
        "request.urlretrieve(\"https://github.com/plushvoxel/Project-Lernende-Agenten-Data-Generator/blob/master/iq.tar?raw=true\", \"iq.tar\")\n",
        "tar = taropen(\"iq.tar\")\n",
        "\n",
        "data = dict()\n",
        "MODKEY = \"mod\"\n",
        "\n",
        "for member in tar.getmembers():\n",
        "  \n",
        "  modulation = member.name[3:5]\n",
        "  if modulation == \"am\":\n",
        "    modulation = 1\n",
        "  else:\n",
        "    modulation = 0\n",
        "  if not MODKEY in data:\n",
        "    data[MODKEY] = [modulation]\n",
        "  else:\n",
        "    data[MODKEY].append(modulation)\n",
        "  with tar.extractfile(member) as f:\n",
        "    buffer = f.read()\n",
        "    num_floats = len(buffer)//4\n",
        "    floats = unpack(\"f\"*num_floats, buffer)\n",
        "    i = floats[0::2]\n",
        "    q = floats[1::2]\n",
        "    for j in range(len(i)):\n",
        "      ikey = \"i{:05d}\".format(j)\n",
        "      qkey = \"q{:05d}\".format(j)\n",
        "      if not ikey in data:\n",
        "        data[ikey] = [i[j]]\n",
        "      else:\n",
        "        data[ikey].append(i[j])\n",
        "      if not qkey in data:\n",
        "        data[qkey] = [q[j]]\n",
        "      else:\n",
        "        data[qkey].append(q[j])\n",
        "        \n",
        "signal_dataframe = pd.DataFrame(data=data)\n",
        "signal_dataframe = signal_dataframe.reindex(\n",
        "    np.random.permutation(signal_dataframe.index))\n",
        "print(signal_dataframe)"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    i00000  i00001  i00002  i00003  i00004  i00005  i00006  i00007  i00008  \\\n",
            "56    -0.2     0.7     1.0     0.5    -0.4    -1.0    -0.7     0.1     0.9   \n",
            "6      0.0     0.0     0.0    -0.0     0.0     0.0     0.0     0.0    -0.0   \n",
            "46    -0.0     0.0    -0.0     0.0    -0.0    -0.0     0.0     0.0    -0.0   \n",
            "98     0.3     1.0    -0.9    -0.6    -0.4     0.1    -0.5    -0.9     0.2   \n",
            "12     1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0   \n",
            "..     ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
            "21     1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0   \n",
            "36     1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0   \n",
            "70     1.0     0.9     1.0    -0.9     0.5     0.7    -0.7     0.1    -0.8   \n",
            "37     1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0   \n",
            "34     1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0   \n",
            "\n",
            "    i00009   ...    q02038  q02039  q02040  q02041  q02042  q02043  q02044  \\\n",
            "56     0.9   ...      -0.1    -0.9    -0.9    -0.2     0.7     1.0     0.5   \n",
            "6      0.0   ...       0.0    -0.0    -0.0     0.0     0.0    -0.0    -0.0   \n",
            "46    -0.0   ...       0.0     0.0    -0.0     0.0    -0.0    -0.0    -0.0   \n",
            "98     0.3   ...      -1.0    -0.9    -0.9    -1.0    -1.0    -0.9    -1.0   \n",
            "12     1.0   ...       0.0     0.0    -0.0     0.0    -0.0     0.0     0.0   \n",
            "..     ...   ...       ...     ...     ...     ...     ...     ...     ...   \n",
            "21     1.0   ...       0.0    -0.0    -0.0    -0.0    -0.0     0.0    -0.0   \n",
            "36     1.0   ...       0.0    -0.0    -0.0     0.0     0.0    -0.0     0.0   \n",
            "70    -0.8   ...      -0.3    -1.0     0.9     0.6     0.4    -0.1     0.5   \n",
            "37     1.0   ...      -0.0     0.0    -0.0     0.0    -0.0     0.0    -0.0   \n",
            "34     1.0   ...      -0.0     0.0    -0.0    -0.0     0.0    -0.0    -0.0   \n",
            "\n",
            "    q02045  q02046  q02047  \n",
            "56    -0.4    -1.0    -0.7  \n",
            "6      0.0     0.0     0.0  \n",
            "46    -0.0    -0.0    -0.0  \n",
            "98    -0.9    -0.9    -1.0  \n",
            "12     0.0    -0.0     0.0  \n",
            "..     ...     ...     ...  \n",
            "21    -0.0    -0.0     0.0  \n",
            "36     0.0     0.0    -0.0  \n",
            "70     0.9    -0.1    -0.3  \n",
            "37     0.0     0.0    -0.0  \n",
            "34    -0.0    -0.0    -0.0  \n",
            "\n",
            "[110 rows x 4097 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pQzcj2B1T5dA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess_features(signal_dataframe):\n",
        "  \"\"\"Prepares input features from California housing data set.\n",
        "\n",
        "  Args:\n",
        "    signal_dataframe: A Pandas DataFrame expected to contain data\n",
        "      from the Radio Signal data set.\n",
        "  Returns:\n",
        "    A DataFrame that contains the features to be used for the model, including\n",
        "    synthetic features.\n",
        "  \"\"\"\n",
        "  selected_features = signal_dataframe.loc[:,'i00000':]\n",
        "  processed_features = selected_features.copy()\n",
        "  \n",
        "  print(signal_dataframe.shape[0])\n",
        "  return processed_features\n",
        "\n",
        "def preprocess_targets(signal_dataframe):\n",
        "  \"\"\"Prepares target features (i.e., labels) from Radio signal data set.\n",
        "\n",
        "  Args:\n",
        "    signal_dataframe: A Pandas DataFrame expected to contain data\n",
        "      from the Radio signal data set.\n",
        "  Returns:\n",
        "    A DataFrame that contains the target feature.\n",
        "  \"\"\"\n",
        "  output_targets = pd.DataFrame()\n",
        "  output_targets[MODKEY] = signal_dataframe[MODKEY]\n",
        "  return output_targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9b--AVj2XPs3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "64867487-d3ee-4bdc-bb3a-ea8e85ff41a4"
      },
      "cell_type": "code",
      "source": [
        "training_examples = preprocess_features(signal_dataframe.head(training_set_size))\n",
        "training_examples.describe()"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>i00000</th>\n",
              "      <th>i00001</th>\n",
              "      <th>i00002</th>\n",
              "      <th>i00003</th>\n",
              "      <th>i00004</th>\n",
              "      <th>i00005</th>\n",
              "      <th>i00006</th>\n",
              "      <th>i00007</th>\n",
              "      <th>i00008</th>\n",
              "      <th>i00009</th>\n",
              "      <th>...</th>\n",
              "      <th>q02038</th>\n",
              "      <th>q02039</th>\n",
              "      <th>q02040</th>\n",
              "      <th>q02041</th>\n",
              "      <th>q02042</th>\n",
              "      <th>q02043</th>\n",
              "      <th>q02044</th>\n",
              "      <th>q02045</th>\n",
              "      <th>q02046</th>\n",
              "      <th>q02047</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>...</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.4</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.4</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.7</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.7</td>\n",
              "      <td>...</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-0.1</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.9</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.9</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 4097 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       i00000  i00001  i00002  i00003  i00004  i00005  i00006  i00007  i00008  \\\n",
              "count   100.0   100.0   100.0   100.0   100.0   100.0   100.0   100.0   100.0   \n",
              "mean      0.4     0.4     0.5     0.5     0.5     0.5     0.4     0.4     0.4   \n",
              "std       0.7     0.8     0.7     0.7     0.6     0.7     0.7     0.7     0.7   \n",
              "min      -1.0    -1.0    -1.0    -1.0    -1.0    -1.0    -1.0    -1.0    -1.0   \n",
              "25%      -0.1    -0.5     0.0     0.0     0.1     0.0    -0.1     0.0    -0.2   \n",
              "50%       0.9     0.9     1.0     1.0     1.0     0.9     0.9     1.0     0.9   \n",
              "75%       1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0   \n",
              "max       1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0   \n",
              "\n",
              "       i00009   ...    q02038  q02039  q02040  q02041  q02042  q02043  q02044  \\\n",
              "count   100.0   ...     100.0   100.0   100.0   100.0   100.0   100.0   100.0   \n",
              "mean      0.4   ...       0.0     0.0    -0.0    -0.0    -0.1     0.0     0.0   \n",
              "std       0.7   ...       0.5     0.5     0.5     0.5     0.5     0.5     0.5   \n",
              "min      -1.0   ...      -1.0    -1.0    -1.0    -1.0    -1.0    -1.0    -1.0   \n",
              "25%      -0.0   ...      -0.1    -0.0    -0.1    -0.0    -0.1    -0.0    -0.0   \n",
              "50%       0.9   ...      -0.0     0.0    -0.0     0.0    -0.0    -0.0     0.0   \n",
              "75%       1.0   ...       0.0     0.0     0.0     0.0     0.0     0.0     0.2   \n",
              "max       1.0   ...       1.0     1.0     1.0     1.0     1.0     1.0     1.0   \n",
              "\n",
              "       q02045  q02046  q02047  \n",
              "count   100.0   100.0   100.0  \n",
              "mean     -0.0     0.0     0.1  \n",
              "std       0.5     0.5     0.5  \n",
              "min      -1.0    -1.0    -1.0  \n",
              "25%      -0.1    -0.0    -0.0  \n",
              "50%      -0.0    -0.0     0.0  \n",
              "75%       0.0     0.1     0.0  \n",
              "max       1.0     1.0     1.0  \n",
              "\n",
              "[8 rows x 4097 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "metadata": {
        "id": "h5ecpnqjXcIL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "642812e3-6ada-4ea6-8da1-6caaf0bc5544"
      },
      "cell_type": "code",
      "source": [
        "training_targets = preprocess_targets(signal_dataframe.head(training_set_size))\n",
        "training_targets.describe()"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mod</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        mod\n",
              "count 100.0\n",
              "mean    0.5\n",
              "std     0.5\n",
              "min     0.0\n",
              "25%     0.0\n",
              "50%     0.0\n",
              "75%     1.0\n",
              "max     1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "metadata": {
        "id": "1qhy5_wDblQC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "ee27eb7b-408a-4467-9b9d-2c9481de2b7b"
      },
      "cell_type": "code",
      "source": [
        "validation_examples = preprocess_features(signal_dataframe.tail(test_set_size))\n",
        "validation_examples.describe()"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>i00000</th>\n",
              "      <th>i00001</th>\n",
              "      <th>i00002</th>\n",
              "      <th>i00003</th>\n",
              "      <th>i00004</th>\n",
              "      <th>i00005</th>\n",
              "      <th>i00006</th>\n",
              "      <th>i00007</th>\n",
              "      <th>i00008</th>\n",
              "      <th>i00009</th>\n",
              "      <th>...</th>\n",
              "      <th>q02038</th>\n",
              "      <th>q02039</th>\n",
              "      <th>q02040</th>\n",
              "      <th>q02041</th>\n",
              "      <th>q02042</th>\n",
              "      <th>q02043</th>\n",
              "      <th>q02044</th>\n",
              "      <th>q02045</th>\n",
              "      <th>q02046</th>\n",
              "      <th>q02047</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>...</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.9</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.5</td>\n",
              "      <td>...</td>\n",
              "      <td>0.1</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.3</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.8</td>\n",
              "      <td>...</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.1</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.9</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>0.1</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>-0.9</td>\n",
              "      <td>-0.8</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>-0.9</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>-0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.3</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 4097 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       i00000  i00001  i00002  i00003  i00004  i00005  i00006  i00007  i00008  \\\n",
              "count    10.0    10.0    10.0    10.0    10.0    10.0    10.0    10.0    10.0   \n",
              "mean      0.9     0.5     0.7     0.6     0.5     0.8     0.6     0.5     0.6   \n",
              "std       0.3     0.8     0.6     0.8     0.7     0.3     0.7     0.7     0.7   \n",
              "min       0.1    -1.0    -1.0    -0.9    -0.7     0.1    -0.7    -0.9    -0.8   \n",
              "25%       1.0     0.2     1.0     0.7     0.3     0.8     0.8     0.1     0.8   \n",
              "50%       1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0   \n",
              "75%       1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0   \n",
              "max       1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0   \n",
              "\n",
              "       i00009   ...    q02038  q02039  q02040  q02041  q02042  q02043  q02044  \\\n",
              "count    10.0   ...      10.0    10.0    10.0    10.0    10.0    10.0    10.0   \n",
              "mean      0.5   ...       0.1    -0.1     0.1     0.1    -0.1     0.1     0.1   \n",
              "std       0.8   ...       0.4     0.5     0.4     0.5     0.6     0.2     0.3   \n",
              "min      -1.0   ...      -0.3    -1.0    -0.5    -0.9    -1.0    -0.2    -0.5   \n",
              "25%       0.3   ...      -0.0    -0.0    -0.0    -0.0    -0.0    -0.0    -0.0   \n",
              "50%       1.0   ...       0.0    -0.0    -0.0    -0.0     0.0    -0.0    -0.0   \n",
              "75%       1.0   ...       0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "max       1.0   ...       1.0     0.7     0.9     0.9     0.9     0.5     0.7   \n",
              "\n",
              "       q02045  q02046  q02047  \n",
              "count    10.0    10.0    10.0  \n",
              "mean      0.2     0.0    -0.1  \n",
              "std       0.6     0.4     0.4  \n",
              "min      -1.0    -0.7    -0.8  \n",
              "25%      -0.0    -0.0    -0.3  \n",
              "50%       0.0    -0.0    -0.0  \n",
              "75%       0.7     0.0    -0.0  \n",
              "max       1.0     0.9     0.8  \n",
              "\n",
              "[8 rows x 4097 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "metadata": {
        "id": "P9RTKvE8b0Hm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "22b43e6b-ab88-4992-913c-2454d51cc405"
      },
      "cell_type": "code",
      "source": [
        "validation_targets = preprocess_targets(signal_dataframe.tail(test_set_size))\n",
        "validation_targets.describe()"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mod</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       mod\n",
              "count 10.0\n",
              "mean   0.6\n",
              "std    0.5\n",
              "min    0.0\n",
              "25%    0.0\n",
              "50%    1.0\n",
              "75%    1.0\n",
              "max    1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "metadata": {
        "id": "RWq0xecNKNeG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Building a Neural Network\n",
        "\n",
        "The NN is defined by the [DNNRegressor](https://www.tensorflow.org/api_docs/python/tf/estimator/DNNRegressor) class.\n",
        "\n",
        "Use **`hidden_units`** to define the structure of the NN.  The `hidden_units` argument provides a list of ints, where each int corresponds to a hidden layer and indicates the number of nodes in it.  For example, consider the following assignment:\n",
        "\n",
        "`hidden_units=[3,10]`\n",
        "\n",
        "The preceding assignment specifies a neural net with two hidden layers:\n",
        "\n",
        "* The first hidden layer contains 3 nodes.\n",
        "* The second hidden layer contains 10 nodes.\n",
        "\n",
        "If we wanted to add more layers, we'd add more ints to the list. For example, `hidden_units=[10,20,30,40]` would create four layers with ten, twenty, thirty, and forty units, respectively.\n",
        "\n",
        "By default, all hidden layers will use ReLu activation and will be fully connected."
      ]
    },
    {
      "metadata": {
        "id": "ni0S6zHcTb04",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def construct_feature_columns(input_features):\n",
        "  \"\"\"Construct the TensorFlow Feature Columns.\n",
        "\n",
        "  Args:\n",
        "    input_features: The names of the numerical input features to use.\n",
        "  Returns:\n",
        "    A set of feature columns\n",
        "  \"\"\" \n",
        "  return set([tf.feature_column.numeric_column(my_feature)\n",
        "              for my_feature in input_features])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zvCqgNdzpaFg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):\n",
        "    \"\"\"Trains a neural net regression model.\n",
        "  \n",
        "    Args:\n",
        "      features: pandas DataFrame of features\n",
        "      targets: pandas DataFrame of targets\n",
        "      batch_size: Size of batches to be passed to the model\n",
        "      shuffle: True or False. Whether to shuffle the data.\n",
        "      num_epochs: Number of epochs for which data should be repeated. None = repeat indefinitely\n",
        "    Returns:\n",
        "      Tuple of (features, labels) for next data batch\n",
        "    \"\"\"\n",
        "    \n",
        "    # Convert pandas data into a dict of np arrays.\n",
        "    features = {key:np.array(value) for key,value in dict(features).items()}                                             \n",
        " \n",
        "    # Construct a dataset, and configure batching/repeating.\n",
        "    ds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit\n",
        "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
        "    \n",
        "    # Shuffle the data, if specified.\n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(10000)\n",
        "    \n",
        "    # Return the next batch of data.\n",
        "    features, labels = ds.make_one_shot_iterator().get_next()\n",
        "    return features, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U52Ychv9KNeH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_nn_regression_model(\n",
        "    learning_rate,\n",
        "    steps,\n",
        "    batch_size,\n",
        "    hidden_units,\n",
        "    training_examples,\n",
        "    training_targets,\n",
        "    validation_examples,\n",
        "    validation_targets):\n",
        "  \"\"\"Trains a neural network regression model.\n",
        "  \n",
        "  In addition to training, this function also prints training progress information,\n",
        "  as well as a plot of the training and validation loss over time.\n",
        "  \n",
        "  Args:\n",
        "    learning_rate: A `float`, the learning rate.\n",
        "    steps: A non-zero `int`, the total number of training steps. A training step\n",
        "      consists of a forward and backward pass using a single batch.\n",
        "    batch_size: A non-zero `int`, the batch size.\n",
        "    hidden_units: A `list` of int values, specifying the number of neurons in each layer.\n",
        "    training_examples: A `DataFrame` containing one or more columns from\n",
        "      `signal_dataframe` to use as input features for training.\n",
        "    training_targets: A `DataFrame` containing exactly one column from\n",
        "      `signal_dataframe` to use as target for training.\n",
        "    validation_examples: A `DataFrame` containing one or more columns from\n",
        "      `signal_dataframe` to use as input features for validation.\n",
        "    validation_targets: A `DataFrame` containing exactly one column from\n",
        "      `signal_dataframe` to use as target for validation.\n",
        "      \n",
        "  Returns:\n",
        "    A `DNNRegressor` object trained on the training data.\n",
        "  \"\"\"\n",
        "\n",
        "  periods = 10\n",
        "  steps_per_period = steps / periods\n",
        "  \n",
        "  # Create a DNNRegressor object.\n",
        "  my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "  my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
        "  dnn_regressor = tf.estimator.DNNRegressor(\n",
        "      feature_columns=construct_feature_columns(training_examples),\n",
        "      hidden_units=hidden_units,\n",
        "      optimizer=my_optimizer,\n",
        "  )\n",
        "  \n",
        "  # Create input functions.\n",
        "  training_input_fn = lambda: my_input_fn(training_examples, \n",
        "                                          training_targets[MODKEY], \n",
        "                                          batch_size=batch_size)\n",
        "  predict_training_input_fn = lambda: my_input_fn(training_examples, \n",
        "                                                  training_targets[MODKEY], \n",
        "                                                  num_epochs=1, \n",
        "                                                  shuffle=False)\n",
        "  predict_validation_input_fn = lambda: my_input_fn(validation_examples, \n",
        "                                                    validation_targets[MODKEY], \n",
        "                                                    num_epochs=1, \n",
        "                                                    shuffle=False)\n",
        "\n",
        "  # Train the model, but do so inside a loop so that we can periodically assess\n",
        "  # loss metrics.\n",
        "  print(\"Training model...\")\n",
        "  print(\"RMSE (on training data):\")\n",
        "  training_rmse = []\n",
        "  validation_rmse = []\n",
        "  for period in range (0, periods):\n",
        "    # Train the model, starting from the prior state.\n",
        "    dnn_regressor.train(\n",
        "        input_fn=training_input_fn,\n",
        "        steps=steps_per_period\n",
        "    )\n",
        "    # Take a break and compute predictions.\n",
        "    training_predictions = dnn_regressor.predict(input_fn=predict_training_input_fn)\n",
        "    training_predictions = np.array([item['predictions'][0] for item in training_predictions])\n",
        "    \n",
        "    validation_predictions = dnn_regressor.predict(input_fn=predict_validation_input_fn)\n",
        "    validation_predictions = np.array([item['predictions'][0] for item in validation_predictions])\n",
        "    \n",
        "    # Compute training and validation loss.\n",
        "    training_root_mean_squared_error = math.sqrt(\n",
        "        metrics.mean_squared_error(training_predictions, training_targets))\n",
        "    validation_root_mean_squared_error = math.sqrt(\n",
        "        metrics.mean_squared_error(validation_predictions, validation_targets))\n",
        "    # Occasionally print the current loss.\n",
        "    print(\"  period %02d : %0.2f\" % (period, training_root_mean_squared_error))\n",
        "    # Add the loss metrics from this period to our list.\n",
        "    training_rmse.append(training_root_mean_squared_error)\n",
        "    validation_rmse.append(validation_root_mean_squared_error)\n",
        "  print(\"Model training finished.\")\n",
        "\n",
        "  # Output a graph of loss metrics over periods.\n",
        "  plt.ylabel(\"RMSE\")\n",
        "  plt.xlabel(\"Periods\")\n",
        "  plt.title(\"Root Mean Squared Error vs. Periods\")\n",
        "  plt.tight_layout()\n",
        "  plt.plot(training_rmse, label=\"training\")\n",
        "  plt.plot(validation_rmse, label=\"validation\")\n",
        "  plt.legend()\n",
        "\n",
        "  print(\"Final RMSE (on training data):   %0.2f\" % training_root_mean_squared_error)\n",
        "  print(\"Final RMSE (on validation data): %0.2f\" % validation_root_mean_squared_error)\n",
        "\n",
        "  return dnn_regressor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IjkpSqmxqnSM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        },
        "outputId": "42ca8c81-822a-4f9a-a247-19907cb7771a"
      },
      "cell_type": "code",
      "source": [
        "dnn_regressor = train_nn_regression_model(\n",
        "    learning_rate=learning_rate,\n",
        "    steps=steps,\n",
        "    batch_size=batch_size,\n",
        "    hidden_units=model,\n",
        "    training_examples=training_examples,\n",
        "    training_targets=training_targets,\n",
        "    validation_examples=validation_examples,\n",
        "    validation_targets=validation_targets)"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model...\n",
            "RMSE (on training data):\n",
            "  period 00 : 1.46\n",
            "  period 01 : 2.02\n",
            "  period 02 : 1.81\n",
            "  period 03 : 1.25\n",
            "  period 04 : 1.32\n",
            "  period 05 : 1.36\n",
            "  period 06 : 2.66\n",
            "  period 07 : 8.25\n",
            "  period 08 : 3.21\n",
            "  period 09 : 2.94\n",
            "Model training finished.\n",
            "Final RMSE (on training data):   2.94\n",
            "Final RMSE (on validation data): 1.80\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAGACAYAAACDX0mmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEEIIoVoSVIQQQgihWv8fvPcMTcQ5iWkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f5a07452320>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}